---
title: "Rank Product Tests"
author: "Hannah Butler"
date: "7/16/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

## Finals Data
load("rp_data.rdata")
```

# About the Rank Product 
The Rank-Product test is a nonparametric test developed with the use in replicated gene expression experiments in mind. The idea is that we have $k$ sets of rankings for $n$ genes and want to know if a gene is differentially expressed. (A gene is declared differentially expressed if an observed difference or change in read counts or expression levels between two experimental conditions is statistically significant https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4827276/ ). Outside of biology, this test also has applications in statistical meta-analysis and feature selection.

If the rankings are balanced (that is, if each item has an equal number of replicates), then the rank-product $RP$ statistic for item $i$ can simply be computed as the geometric mean of the rankings $r_{ij}$ across the $k$ replicates for item $i = 1, \dots, n$ and replicate $j = 1,\dots, k$ :

$$ RP_i = \Big( \prod_{j=1}^{k} r_{ij} \Big)^{1/k} $$

https://febs.onlinelibrary.wiley.com/doi/epdf/10.1016/j.febslet.2004.07.055

## Determining Significance Level

# Application to Olympic Sport Climbing
We believe this nonparametric test can be usefully applied to scoring data for the combined sport climbing events. We consider each of the 3 events a "replicate" for each climber, giving us $k=3$ sets of rankings. We then compute the rank product statistic for each climber, and compare it to a distribution of corresponding simulated rank products generated by uniformly and independently drawing a permutation of ranks for each event. Our test is to challenge this assumption that a climber's ranking is randomly achieved with equal odds.

## Function to Generate Rank-Product Permutations
```{r}
assign_ranks <- function(c = 8) {
  # randomly assign ranks in 3 events & compute product across events
  # ranking in an event is considered to be independent from ranking in another event
  output <- cbind(sample(1:c, c, replace = FALSE)
                  , sample(1:c, c, replace = FALSE)
                  , sample(1:c, c, replace = FALSE)
                  ) %>%
    apply(1, prod)
  
  return(output)
}
```

```{r}
compare_rp <- function(rp_real, rp_perm) {
  # count how many of the permuted rank-products are smaller than the real rank-product
  sum(rp_real >= rp_perm) %>%
  return()
}

nsim <- 1000
nqual <- nrow(m_qual_rp)
rp_sims <- replicate(nsim, assign_ranks(nqual))
df <- data.frame(first = rep(NA, nqual)
                 , last = rep(NA, nqual)
                 , speed = rep(NA, nqual)
                 , bould = rep(NA, nqual)
                 , lead = rep(NA, nqual)
                 , total = rep(NA, nqual)
                 , count_above = rep(NA, nqual)
                 , E = rep(NA, nqual)
                 , q = rep(NA, nqual)
                 )

for (i in 1:nqual) {
  t <- m_qual_rp$total[i]                                            # experimental/real score
  #cat(m_qual_rp$first[i], m_qual_rp$last[i], " ", t, "\n")
  s <-  compare_rp(t, rp_sims) %>% sum()                             # count which simulated rp values <= real rp
  e <- s/nsim                                                        # avg expected value
  q <- e/i                                                           # q value (false discovery rate)
  #print(q)
  df[i,] <- c(m_qual_rp$first[i]
              , m_qual_rp$last[i]
              , m_qual_rp$speed[i]
              , m_qual_rp$bould[i]
              , m_qual_rp$lead[i]
              , m_qual_rp$total[i]
              , s
              , e
              , q
              )
}

df %>% knitr::kable()
```